{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c2730609",
      "metadata": {
        "id": "c2730609"
      },
      "source": [
        "## üì¶ 1. Configuration de l'environnement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d1542762",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1542762",
        "outputId": "b35859eb-1cbe-473e-c3a5-c00794d3fa7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Ex√©cution sur Google Colab\n"
          ]
        }
      ],
      "source": [
        "# V√©rifier si on est sur Colab\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"‚úì Ex√©cution sur Google Colab\")\n",
        "else:\n",
        "    print(\"‚úì Ex√©cution en local\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "db68af0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db68af0e",
        "outputId": "b54ec05d-4f83-48d8-cd76-e1c883dc26b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting networkx==3.2.1\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: networkx\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.6.1\n",
            "    Uninstalling networkx-3.6.1:\n",
            "      Successfully uninstalled networkx-3.6.1\n",
            "Successfully installed networkx-3.2.1\n"
          ]
        }
      ],
      "source": [
        "# Installation des d√©pendances sur Colab\n",
        "if IN_COLAB:\n",
        "    !pip install networkx==3.2.1 pandas matplotlib seaborn scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c16602f7",
      "metadata": {
        "id": "c16602f7"
      },
      "source": [
        "## üìÇ 2. Clonage du d√©p√¥t GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f1696523",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1696523",
        "outputId": "06dd46fa-a41d-4aa4-80a0-8351484c4824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NSGL-Projet'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "[Errno 2] No such file or directory: '/content/NSGL-Projet'\n",
            "/content\n",
            "üìÅ Dossier de travail: /content\n",
            "üìÑ Fichiers Python disponibles:\n",
            "ls: cannot access '*.py': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Cloner le repo si pas d√©j√† fait\n",
        "    if not os.path.exists('/content/NSGL-Projet'):\n",
        "        !git clone https://github.com/tanguycesar/NSGL-Projet.git\n",
        "        %cd /content/NSGL-Projet\n",
        "    else:\n",
        "        %cd /content/NSGL-Projet\n",
        "        !git pull\n",
        "\n",
        "    print(f\"üìÅ Dossier de travail: {os.getcwd()}\")\n",
        "    print(f\"üìÑ Fichiers Python disponibles:\")\n",
        "    !ls -l *.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3658dcf2",
      "metadata": {
        "id": "3658dcf2"
      },
      "source": [
        "## üåê 3. T√©l√©chargement des donn√©es Facebook100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3c948e0",
      "metadata": {
        "id": "b3c948e0"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "data_dir = 'facebook100' if not IN_COLAB else '/content/NSGL-Projet/facebook100'\n",
        "\n",
        "# T√©l√©charger si pas d√©j√† pr√©sent\n",
        "if not os.path.exists(data_dir) or len([f for f in os.listdir(data_dir) if f.endswith('.gml')]) == 0:\n",
        "    print(\"üì• T√©l√©chargement des donn√©es Facebook100...\")\n",
        "\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    url = 'https://gitlab.imt-atlantique.fr/boucheddf/projects-tried/-/raw/main/facebook100.zip'\n",
        "    zip_path = os.path.join(data_dir, 'facebook100.zip')\n",
        "\n",
        "    urllib.request.urlretrieve(url, zip_path)\n",
        "    print(f\"‚úì T√©l√©chargement termin√©: {zip_path}\")\n",
        "\n",
        "    # Extraire\n",
        "    print(\"üì¶ Extraction...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "\n",
        "    os.remove(zip_path)\n",
        "    print(\"‚úì Extraction termin√©e\")\n",
        "else:\n",
        "    print(\"‚úì Donn√©es Facebook100 d√©j√† pr√©sentes\")\n",
        "\n",
        "# Lister les r√©seaux\n",
        "gml_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.gml')])\n",
        "print(f\"\\nüìä {len(gml_files)} r√©seaux disponibles\")\n",
        "print(\"Exemples:\", gml_files[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00296506",
      "metadata": {
        "id": "00296506"
      },
      "source": [
        "## üîß 4. Imports et configuration GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f3cd96d",
      "metadata": {
        "id": "5f3cd96d"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, mean_absolute_error\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration graphiques\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Configuration GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"üñ•Ô∏è  Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   M√©moire: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "725a5478",
      "metadata": {
        "id": "725a5478"
      },
      "source": [
        "---\n",
        "# Question 4: Link Prediction\n",
        "## Pr√©diction de liens avec m√©triques manuelles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8701c9f6",
      "metadata": {
        "id": "8701c9f6"
      },
      "source": [
        "### 4.1 Impl√©mentation des m√©triques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37aaef0e",
      "metadata": {
        "id": "37aaef0e"
      },
      "outputs": [],
      "source": [
        "def common_neighbors_score(G, u, v, neighbors_dict):\n",
        "    \"\"\"Common Neighbors: |Œì(u) ‚à© Œì(v)|\"\"\"\n",
        "    return len(neighbors_dict[u] & neighbors_dict[v])\n",
        "\n",
        "def jaccard_score(G, u, v, neighbors_dict):\n",
        "    \"\"\"Jaccard: |Œì(u) ‚à© Œì(v)| / |Œì(u) ‚à™ Œì(v)|\"\"\"\n",
        "    intersection = len(neighbors_dict[u] & neighbors_dict[v])\n",
        "    union = len(neighbors_dict[u] | neighbors_dict[v])\n",
        "    return intersection / union if union > 0 else 0\n",
        "\n",
        "def adamic_adar_score(G, u, v, neighbors_dict):\n",
        "    \"\"\"Adamic-Adar: Œ£_{w ‚àà Œì(u) ‚à© Œì(v)} 1 / log(|Œì(w)|)\"\"\"\n",
        "    common = neighbors_dict[u] & neighbors_dict[v]\n",
        "    score = 0\n",
        "    for w in common:\n",
        "        degree_w = len(neighbors_dict[w])\n",
        "        if degree_w > 1:\n",
        "            score += 1.0 / np.log(degree_w)\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e31f8e8",
      "metadata": {
        "id": "0e31f8e8"
      },
      "source": [
        "### 4.2 G√©n√©ration des paires candidates (optimis√©)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ded5109a",
      "metadata": {
        "id": "ded5109a"
      },
      "outputs": [],
      "source": [
        "def get_candidate_pairs(G, max_candidates=50000):\n",
        "    \"\"\"\n",
        "    G√©n√®re des paires candidates en limitant √† max_candidates.\n",
        "    Optimisations:\n",
        "    - Limite de 50k paires (suffisant pour k=400)\n",
        "    - √âchantillonnage pour n≈ìuds > 100 voisins\n",
        "    - V√©rification O(1) avec set\n",
        "    \"\"\"\n",
        "    edges_set = set(G.edges())\n",
        "    candidates = []\n",
        "\n",
        "    nodes = list(G.nodes())\n",
        "    random.shuffle(nodes)  # Diversit√©\n",
        "\n",
        "    neighbors_dict = {n: set(G.neighbors(n)) for n in G.nodes()}\n",
        "\n",
        "    for u in nodes:\n",
        "        if len(candidates) >= max_candidates:\n",
        "            break\n",
        "\n",
        "        neighbors_u = neighbors_dict[u]\n",
        "\n",
        "        # Voisins de voisins\n",
        "        neighbors_of_neighbors = set()\n",
        "        for neighbor in neighbors_u:\n",
        "            neighbor_neighbors = neighbors_dict[neighbor]\n",
        "\n",
        "            # √âchantillonner si trop de voisins\n",
        "            if len(neighbor_neighbors) > 100:\n",
        "                neighbor_neighbors = set(random.sample(list(neighbor_neighbors), 100))\n",
        "\n",
        "            neighbors_of_neighbors.update(neighbor_neighbors)\n",
        "\n",
        "        # Paires non connect√©es\n",
        "        for v in neighbors_of_neighbors:\n",
        "            if v != u and v not in neighbors_u:\n",
        "                edge = tuple(sorted([u, v]))\n",
        "                if edge not in edges_set:\n",
        "                    candidates.append((u, v))\n",
        "\n",
        "                    if len(candidates) >= max_candidates:\n",
        "                        break\n",
        "\n",
        "    return candidates, neighbors_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "969830d6",
      "metadata": {
        "id": "969830d6"
      },
      "source": [
        "### 4.3 Fonction d'√©valuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61fc0b06",
      "metadata": {
        "id": "61fc0b06"
      },
      "outputs": [],
      "source": [
        "def evaluate_predictor(G, predictor_name, f_values, k_values, max_candidates=50000):\n",
        "    \"\"\"\n",
        "    √âvalue un pr√©dicteur sur diff√©rentes fractions et valeurs de k\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for f in f_values:\n",
        "        print(f\"  üìä Fraction {f:.0%}...\", end=\" \")\n",
        "\n",
        "        # Supprimer f% des ar√™tes\n",
        "        edges = list(G.edges())\n",
        "        num_remove = int(len(edges) * f)\n",
        "        removed_edges = random.sample(edges, num_remove)\n",
        "\n",
        "        G_train = G.copy()\n",
        "        G_train.remove_edges_from(removed_edges)\n",
        "        removed_set = set(tuple(sorted(e)) for e in removed_edges)\n",
        "\n",
        "        # G√©n√©rer candidates\n",
        "        candidates, neighbors_dict = get_candidate_pairs(G_train, max_candidates)\n",
        "\n",
        "        # Calculer scores\n",
        "        scores = []\n",
        "        for u, v in candidates:\n",
        "            if predictor_name == \"CommonNeighbors\":\n",
        "                score = common_neighbors_score(G_train, u, v, neighbors_dict)\n",
        "            elif predictor_name == \"Jaccard\":\n",
        "                score = jaccard_score(G_train, u, v, neighbors_dict)\n",
        "            elif predictor_name == \"AdamicAdar\":\n",
        "                score = adamic_adar_score(G_train, u, v, neighbors_dict)\n",
        "            scores.append((u, v, score))\n",
        "\n",
        "        # Trier par score d√©croissant\n",
        "        scores.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "        # √âvaluer pour chaque k\n",
        "        for k in k_values:\n",
        "            top_k = scores[:k]\n",
        "            top_k_pairs = [tuple(sorted([u, v])) for u, v, _ in top_k]\n",
        "\n",
        "            # Pr√©cision et Rappel\n",
        "            hits = sum(1 for pair in top_k_pairs if pair in removed_set)\n",
        "            precision = hits / k if k > 0 else 0\n",
        "            recall = hits / len(removed_set) if len(removed_set) > 0 else 0\n",
        "\n",
        "            results.append({\n",
        "                'predictor': predictor_name,\n",
        "                'f': f,\n",
        "                'k': k,\n",
        "                'precision': precision,\n",
        "                'recall': recall\n",
        "            })\n",
        "\n",
        "        print(\"‚úì\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da5d758a",
      "metadata": {
        "id": "da5d758a"
      },
      "source": [
        "### 4.4 Ex√©cution sur 15 r√©seaux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e094ce",
      "metadata": {
        "id": "e4e094ce"
      },
      "outputs": [],
      "source": [
        "# S√©lection de 15 r√©seaux (moyens et grands)\n",
        "selected_networks_q4 = [\n",
        "    'Caltech36.gml', 'Reed98.gml', 'Haverford76.gml', 'Swarthmore42.gml', 'Amherst41.gml',\n",
        "    'Hamilton46.gml', 'Colgate88.gml', 'Oberlin44.gml', 'Middlebury45.gml', 'Wellesley22.gml',\n",
        "    'Brandeis99.gml', 'Lehigh96.gml', 'American75.gml', 'Bucknell39.gml', 'Duke14.gml'\n",
        "]\n",
        "\n",
        "# Param√®tres\n",
        "f_values = [0.05, 0.1, 0.15, 0.2]\n",
        "k_values = [50, 100, 200, 300, 400]\n",
        "predictors = [\"CommonNeighbors\", \"Jaccard\", \"AdamicAdar\"]\n",
        "\n",
        "all_results_q4 = []\n",
        "\n",
        "print(\"üöÄ D√©but de l'analyse Question 4...\\n\")\n",
        "\n",
        "for i, network_file in enumerate(selected_networks_q4, 1):\n",
        "    print(f\"üìä [{i}/15] {network_file}\")\n",
        "\n",
        "    network_path = os.path.join(data_dir, network_file)\n",
        "    G = nx.read_gml(network_path)\n",
        "    G = G.to_undirected()\n",
        "\n",
        "    print(f\"   N≈ìuds: {G.number_of_nodes()}, Ar√™tes: {G.number_of_edges()}\")\n",
        "\n",
        "    for predictor in predictors:\n",
        "        print(f\"  üîç {predictor}\")\n",
        "        results = evaluate_predictor(G, predictor, f_values, k_values)\n",
        "\n",
        "        for r in results:\n",
        "            r['network'] = network_file.replace('.gml', '')\n",
        "        all_results_q4.extend(results)\n",
        "\n",
        "    print()\n",
        "\n",
        "# Sauvegarder r√©sultats\n",
        "df_q4 = pd.DataFrame(all_results_q4)\n",
        "df_q4.to_csv('question4_link_prediction_results_all.csv', index=False)\n",
        "print(\"üíæ R√©sultats sauvegard√©s: question4_link_prediction_results_all.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aeddbc7",
      "metadata": {
        "id": "0aeddbc7"
      },
      "source": [
        "### 4.5 Visualisation des r√©sultats agr√©g√©s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bda7f91",
      "metadata": {
        "id": "0bda7f91"
      },
      "outputs": [],
      "source": [
        "# Agr√©ger par pr√©dictor, f, k\n",
        "df_q4_agg = df_q4.groupby(['predictor', 'f', 'k']).agg({\n",
        "    'precision': ['mean', 'std'],\n",
        "    'recall': ['mean', 'std']\n",
        "}).reset_index()\n",
        "\n",
        "df_q4_agg.columns = ['predictor', 'f', 'k', 'precision_mean', 'precision_std', 'recall_mean', 'recall_std']\n",
        "\n",
        "# Graphiques\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Question 4: Link Prediction - R√©sultats Agr√©g√©s (15 r√©seaux)', fontsize=16, fontweight='bold')\n",
        "\n",
        "for i, f in enumerate(f_values):\n",
        "    ax = axes[i // 2, i % 2]\n",
        "    data_f = df_q4_agg[df_q4_agg['f'] == f]\n",
        "\n",
        "    for predictor in predictors:\n",
        "        data_p = data_f[data_f['predictor'] == predictor]\n",
        "        ax.errorbar(data_p['k'], data_p['precision_mean'], yerr=data_p['precision_std'],\n",
        "                    label=predictor, marker='o', capsize=5, linewidth=2)\n",
        "\n",
        "    ax.set_title(f'Fraction f = {f:.0%}', fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('k (nombre de pr√©dictions)', fontsize=12)\n",
        "    ax.set_ylabel('Pr√©cision moyenne', fontsize=12)\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('question4_link_prediction_aggregated.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìà Graphique sauvegard√©: question4_link_prediction_aggregated.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b9fe726",
      "metadata": {
        "id": "3b9fe726"
      },
      "source": [
        "---\n",
        "# Question 5: Label Propagation\n",
        "## Propagation de labels avec GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a2ba184",
      "metadata": {
        "id": "6a2ba184"
      },
      "source": [
        "### 5.1 Impl√©mentation avec PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4337fcdb",
      "metadata": {
        "id": "4337fcdb"
      },
      "outputs": [],
      "source": [
        "def label_propagation_gpu(G, attribute_name, fraction_missing, device='cuda', max_iterations=200):\n",
        "    \"\"\"\n",
        "    Propagation de labels avec PyTorch et matrices sparses GPU\n",
        "    \"\"\"\n",
        "    # Extraire labels\n",
        "    nodes = list(G.nodes())\n",
        "    labels = [G.nodes[n].get(attribute_name, None) for n in nodes]\n",
        "\n",
        "    # Filtrer valeurs manquantes\n",
        "    valid_indices = [i for i, label in enumerate(labels) if label is not None and label != 0]\n",
        "    if len(valid_indices) == 0:\n",
        "        return None\n",
        "\n",
        "    nodes = [nodes[i] for i in valid_indices]\n",
        "    labels = [labels[i] for i in valid_indices]\n",
        "\n",
        "    # Sous-graphe\n",
        "    G_sub = G.subgraph(nodes).copy()\n",
        "    if G_sub.number_of_nodes() == 0:\n",
        "        return None\n",
        "\n",
        "    # Mapping n≈ìuds -> indices\n",
        "    node_to_idx = {node: idx for idx, node in enumerate(G_sub.nodes())}\n",
        "    labels_array = np.array([labels[i] for i in range(len(nodes))])\n",
        "\n",
        "    # Marquer fraction_missing comme inconnus\n",
        "    n = len(labels_array)\n",
        "    num_remove = int(n * fraction_missing)\n",
        "    indices_to_remove = np.random.choice(n, size=num_remove, replace=False)\n",
        "\n",
        "    known_mask = np.ones(n, dtype=bool)\n",
        "    known_mask[indices_to_remove] = False\n",
        "\n",
        "    true_labels = labels_array.copy()\n",
        "    labels_array[~known_mask] = 0  # Inconnu\n",
        "\n",
        "    # Construire matrice d'adjacence sparse\n",
        "    edges = list(G_sub.edges())\n",
        "    edge_index = torch.tensor(\n",
        "        [[node_to_idx[u], node_to_idx[v]] for u, v in edges] +\n",
        "        [[node_to_idx[v], node_to_idx[u]] for u, v in edges],\n",
        "        dtype=torch.long\n",
        "    ).t().to(device)\n",
        "\n",
        "    # Normalisation par degr√©\n",
        "    degrees = torch.bincount(edge_index[0], minlength=n).float().to(device)\n",
        "    degrees[degrees == 0] = 1  # √âviter division par 0\n",
        "    edge_weight = 1.0 / degrees[edge_index[0]]\n",
        "\n",
        "    # Labels sur GPU\n",
        "    labels_tensor = torch.tensor(labels_array, dtype=torch.float32).to(device)\n",
        "    known_mask_tensor = torch.tensor(known_mask, dtype=torch.bool).to(device)\n",
        "\n",
        "    # Propagation it√©rative\n",
        "    for iteration in range(max_iterations):\n",
        "        new_labels = torch.zeros_like(labels_tensor)\n",
        "        new_labels.index_add_(0, edge_index[1], labels_tensor[edge_index[0]] * edge_weight)\n",
        "\n",
        "        # Conserver labels connus\n",
        "        labels_tensor = torch.where(known_mask_tensor, labels_tensor, new_labels)\n",
        "\n",
        "        # Convergence\n",
        "        if iteration > 0 and torch.allclose(labels_tensor, new_labels, atol=1e-4):\n",
        "            break\n",
        "\n",
        "    # Pr√©dictions\n",
        "    predicted_labels = labels_tensor.cpu().numpy()\n",
        "    predicted_labels = np.round(predicted_labels).astype(int)\n",
        "\n",
        "    # √âvaluation\n",
        "    y_true = true_labels[~known_mask]\n",
        "    y_pred = predicted_labels[~known_mask]\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1_score': f1,\n",
        "        'mae': mae,\n",
        "        'num_nodes': n,\n",
        "        'num_missing': num_remove\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b27aab6",
      "metadata": {
        "id": "9b27aab6"
      },
      "source": [
        "### 5.2 Ex√©cution sur 15 r√©seaux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91c59f88",
      "metadata": {
        "id": "91c59f88"
      },
      "outputs": [],
      "source": [
        "# M√™mes 15 r√©seaux\n",
        "selected_networks_q5 = selected_networks_q4\n",
        "\n",
        "# Param√®tres\n",
        "attributes = ['dorm', 'major_index', 'gender']\n",
        "fractions = [0.1, 0.2, 0.3]\n",
        "\n",
        "all_results_q5 = []\n",
        "\n",
        "print(\"üöÄ D√©but de l'analyse Question 5...\\n\")\n",
        "\n",
        "for i, network_file in enumerate(selected_networks_q5, 1):\n",
        "    print(f\"üìä [{i}/15] {network_file}\")\n",
        "\n",
        "    network_path = os.path.join(data_dir, network_file)\n",
        "    G = nx.read_gml(network_path)\n",
        "    G = G.to_undirected()\n",
        "\n",
        "    for attr in attributes:\n",
        "        print(f\"  üè∑Ô∏è  Attribut: {attr}\")\n",
        "\n",
        "        for frac in fractions:\n",
        "            print(f\"    üìâ Fraction: {frac:.0%}\", end=\" \")\n",
        "\n",
        "            result = label_propagation_gpu(G, attr, frac, device=device)\n",
        "\n",
        "            if result:\n",
        "                result.update({\n",
        "                    'network': network_file.replace('.gml', ''),\n",
        "                    'attribute': attr,\n",
        "                    'fraction': frac\n",
        "                })\n",
        "                all_results_q5.append(result)\n",
        "                print(f\"‚úì Acc={result['accuracy']:.3f}\")\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Pas de donn√©es valides\")\n",
        "\n",
        "    print()\n",
        "\n",
        "# Sauvegarder\n",
        "df_q5 = pd.DataFrame(all_results_q5)\n",
        "df_q5.to_csv('question5_label_propagation_detailed.csv', index=False)\n",
        "print(\"üíæ R√©sultats sauvegard√©s: question5_label_propagation_detailed.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b0e71e1",
      "metadata": {
        "id": "9b0e71e1"
      },
      "source": [
        "### 5.3 Visualisation agr√©g√©e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4edf7440",
      "metadata": {
        "id": "4edf7440"
      },
      "outputs": [],
      "source": [
        "# Agr√©ger par attribut et fraction\n",
        "df_q5_agg = df_q5.groupby(['attribute', 'fraction']).agg({\n",
        "    'accuracy': ['mean', 'std'],\n",
        "    'f1_score': ['mean', 'std'],\n",
        "    'mae': ['mean', 'std']\n",
        "}).reset_index()\n",
        "\n",
        "df_q5_agg.columns = ['attribute', 'fraction', 'acc_mean', 'acc_std', 'f1_mean', 'f1_std', 'mae_mean', 'mae_std']\n",
        "\n",
        "# Graphiques\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Question 5: Label Propagation - R√©sultats Agr√©g√©s (15 r√©seaux)', fontsize=16, fontweight='bold')\n",
        "\n",
        "metrics = [('acc_mean', 'acc_std', 'Accuracy'),\n",
        "           ('f1_mean', 'f1_std', 'F1-Score'),\n",
        "           ('mae_mean', 'mae_std', 'MAE')]\n",
        "\n",
        "for i, (mean_col, std_col, title) in enumerate(metrics):\n",
        "    ax = axes[i]\n",
        "\n",
        "    for attr in attributes:\n",
        "        data_attr = df_q5_agg[df_q5_agg['attribute'] == attr]\n",
        "        ax.errorbar(data_attr['fraction'], data_attr[mean_col], yerr=data_attr[std_col],\n",
        "                    label=attr, marker='o', capsize=5, linewidth=2)\n",
        "\n",
        "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Fraction de labels manquants', fontsize=12)\n",
        "    ax.set_ylabel(f'{title} moyen', fontsize=12)\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('question5_label_propagation_aggregated.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìà Graphique sauvegard√©: question5_label_propagation_aggregated.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10af1b94",
      "metadata": {
        "id": "10af1b94"
      },
      "source": [
        "## üì¶ 6. Export des r√©sultats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cb51906",
      "metadata": {
        "id": "8cb51906"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Cr√©er archive ZIP\n",
        "zip_filename = 'results_q4_q5.zip'\n",
        "files_to_zip = [\n",
        "    'question4_link_prediction_results_all.csv',\n",
        "    'question4_link_prediction_aggregated.png',\n",
        "    'question5_label_propagation_detailed.csv',\n",
        "    'question5_label_propagation_aggregated.png'\n",
        "]\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    for file in files_to_zip:\n",
        "        if os.path.exists(file):\n",
        "            zipf.write(file)\n",
        "            print(f\"‚úì Ajout√©: {file}\")\n",
        "\n",
        "print(f\"\\nüì¶ Archive cr√©√©e: {zip_filename}\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "    files.download(zip_filename)\n",
        "    print(\"üì• T√©l√©chargement lanc√©!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e911e299",
      "metadata": {
        "id": "e911e299"
      },
      "source": [
        "## ‚úÖ R√©sum√©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb77983f",
      "metadata": {
        "id": "cb77983f"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üìä R√âSUM√â DE L'ANALYSE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nüîó QUESTION 4 - Link Prediction:\")\n",
        "print(f\"  ‚Ä¢ R√©seaux analys√©s: {len(selected_networks_q4)}\")\n",
        "print(f\"  ‚Ä¢ Pr√©dicteurs: {', '.join(predictors)}\")\n",
        "print(f\"  ‚Ä¢ Fractions: {f_values}\")\n",
        "print(f\"  ‚Ä¢ Valeurs de k: {k_values}\")\n",
        "print(f\"  ‚Ä¢ Total exp√©riences: {len(df_q4)}\")\n",
        "\n",
        "print(f\"\\nüè∑Ô∏è  QUESTION 5 - Label Propagation:\")\n",
        "print(f\"  ‚Ä¢ R√©seaux analys√©s: {len(selected_networks_q5)}\")\n",
        "print(f\"  ‚Ä¢ Attributs: {', '.join(attributes)}\")\n",
        "print(f\"  ‚Ä¢ Fractions: {fractions}\")\n",
        "print(f\"  ‚Ä¢ Device: {device}\")\n",
        "print(f\"  ‚Ä¢ Total exp√©riences: {len(df_q5)}\")\n",
        "\n",
        "print(f\"\\nüìÅ Fichiers g√©n√©r√©s:\")\n",
        "for file in files_to_zip:\n",
        "    if os.path.exists(file):\n",
        "        size_mb = os.path.getsize(file) / 1024 / 1024\n",
        "        print(f\"  ‚úì {file} ({size_mb:.2f} MB)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ ANALYSE TERMIN√âE\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}